{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W9QpA0RFXaeG",
    "ExecuteTime": {
     "end_time": "2023-05-07T21:56:06.780237800Z",
     "start_time": "2023-05-07T21:56:04.601671600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler as lr_scheduler\n",
    "from torchvision import datasets, transforms\n",
    "import model_flower\n",
    "import model_train\n",
    "import model_test\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Set up variables\n",
    "tr_batchsize = 16 # The size of the training batches\n",
    "val_test_batchsize = 16 # The size of the validation / testing batches\n",
    "epochs = 500 # The number of epochs to do\n",
    "validate_steps = 750 # The number of steps to complete before validation\n",
    "learning_rate = 0.00005 # The learning rate to start at\n",
    "load_model = False # If a model should be requested to be loaded, or not\n",
    "save_model = True # If the model should be saved after testing, or not\n",
    "\n",
    "# The actual model variables\n",
    "model = None\n",
    "criterion = None\n",
    "optimizer = None\n",
    "scheduler = None\n",
    "\n",
    "# Model file values. If \"None\", then they haven't loaded successfully\n",
    "md = None\n",
    "lr = None\n",
    "sch = None\n",
    "cri = None\n",
    "opt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 GPUs.\n",
      "Now the deivce is set to cuda:0\n"
     ]
    }
   ],
   "source": [
    "# By default, set to use the CPU\n",
    "deviceFlag = torch.device('cpu')\n",
    "\n",
    "# If a GPU is available, use it\n",
    "if torch.cuda.is_available():\n",
    "    print(f'Found {torch.cuda.device_count()} GPUs.')\n",
    "    deviceFlag = torch.device('cuda:0') # Default to cuda 0, but can be changed.\n",
    "\n",
    "print(f'Now the deivce is set to {deviceFlag}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T21:56:06.855005800Z",
     "start_time": "2023-05-07T21:56:06.783682300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading and Transformations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "training_transforms = transforms.Compose([\n",
    "    # Randomly rotate it 90 degrees\n",
    "    transforms.RandomRotation(90),\n",
    "    # Randomly sharpen the image\n",
    "    transforms.RandomAdjustSharpness(1.5, 0.5),\n",
    "    # Randomly crop an area of the flower of size 224x224\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    # Flip it horizontally, or don't\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # Flip it vertically, or don't\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # Convert the image to a Tensor\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize the Tensor values so that they're easier for the\n",
    "    # model to train from\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], # RGB mean & std estied on ImageNet\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "testing_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], # RGB mean & std estied on ImageNet\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the datasets of the Flower102 images\n",
    "train_dataset = datasets.Flowers102(root = './dataset', split = 'train', transform = training_transforms, download = True)\n",
    "valid_dataset = datasets.Flowers102(root = './dataset', split = 'val', transform = validation_transforms, download = True)\n",
    "test_dataset = datasets.Flowers102(root = './dataset', split = 'test', transform = testing_transforms, download = True)\n",
    "\n",
    "\n",
    "# Create the loaders for the datasets, to be used to train, validate and test the model\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = tr_batchsize,\n",
    "                                           shuffle = True)\n",
    "\n",
    "validate_loader = torch.utils.data.DataLoader(dataset = valid_dataset,\n",
    "                                           batch_size = val_test_batchsize)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = val_test_batchsize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T21:56:07.047034100Z",
     "start_time": "2023-05-07T21:56:06.819170400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model...\n",
      "Model created. Moving the Model to cuda...\n",
      "Moved the Model to cuda.\n"
     ]
    }
   ],
   "source": [
    "loaded_file = False\n",
    "\n",
    "file_name = \"ERROR\"\n",
    "# If going to load a model\n",
    "if load_model:\n",
    "    # First request the file name of a model\n",
    "    file_name = \"models/\" + input(\"Model to load: \")\n",
    "    # And try to load it\n",
    "    if os.path.exists(file_name):\n",
    "        try:\n",
    "            file_data = torch.load(file_name)\n",
    "            md = file_data[\"model\"]\n",
    "            lr = file_data[\"learning_rate\"]\n",
    "            sch = file_data[\"scheduler\"]\n",
    "            cri = file_data[\"criterion\"]\n",
    "            opt = file_data[\"optimizer\"]\n",
    "            loaded_file = True\n",
    "            print(\"Model loaded.\")\n",
    "        except:\n",
    "            # If it fails, load nothing from the file\n",
    "            md = None\n",
    "            lr = learning_rate\n",
    "            sch = None\n",
    "            cri = None\n",
    "            opt = None\n",
    "            print(\"Model failed to load. Using default untrained Model.\")\n",
    "\n",
    "print(\"Creating Model...\")\n",
    "model = model_flower.FlowerModel()\n",
    "print(\"Model created. Moving the Model to \" + deviceFlag.type + \"...\")\n",
    "model.to(deviceFlag)\n",
    "print(\"Moved the Model to \" + deviceFlag.type + \".\")\n",
    "\n",
    "if loaded_file:\n",
    "    print(\"\\nUsing model file from \" + file_name)\n",
    "    model.load_state_dict(md)\n",
    "    learning_rate = lr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T21:56:07.270530600Z",
     "start_time": "2023-05-07T21:56:07.052017800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Loss Function and Optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Negative Log Likelihood Loss\n",
    "# criterion = nn.NLLLoss()\n",
    "\n",
    "# Cross Entropy Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if not cri is None:\n",
    "    criterion.load_state_dict(cri)\n",
    "\n",
    "# optimizer 1\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "if not opt is None:\n",
    "    optimizer.load_state_dict(opt)\n",
    "\n",
    "# optimizer 2\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay = 0.005, momentum = 0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T21:56:07.281645900Z",
     "start_time": "2023-05-07T21:56:07.267428100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m lr_scheduler\u001B[38;5;241m.\u001B[39mStepLR(optimizer, \u001B[38;5;241m500\u001B[39m, learning_rate)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sch \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43msch\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\cudatest\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:102\u001B[0m, in \u001B[0;36mLRScheduler.load_state_dict\u001B[1;34m(self, state_dict)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_state_dict\u001B[39m(\u001B[38;5;28mself\u001B[39m, state_dict):\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;124;03m\"\"\"Loads the schedulers state.\u001B[39;00m\n\u001B[0;32m     97\u001B[0m \n\u001B[0;32m     98\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;124;03m        state_dict (dict): scheduler state. Should be an object returned\u001B[39;00m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;124;03m            from a call to :meth:`state_dict`.\u001B[39;00m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 102\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__dict__\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Scheduler\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 500, learning_rate)\n",
    "if not sch is None:\n",
    "    scheduler.load_state_dict(sch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T21:56:08.558069300Z",
     "start_time": "2023-05-07T21:56:07.282956500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_train.train_classifier(model, train_loader, validate_loader, optimizer, criterion,\n",
    "                             optim_scheduler=scheduler, device_flag=deviceFlag, epochs=epochs,\n",
    "                             validate_steps=validate_steps, validate_stepped=True, validate_epoch=False,\n",
    "                             validate_end=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_test.test_accuracy(model, test_loader, device_flag=deviceFlag)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if save_model:\n",
    "    save_data = {\n",
    "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "        \"model\": model.state_dict(),\n",
    "        \"criterion\": criterion.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict()\n",
    "    }\n",
    "\n",
    "    torch.save(save_data, \"models/\" + str(datetime.datetime.now()).replace(\":\",\"-\")\n",
    "               + f\" b{tr_batchsize}-e{epochs}-lr{learning_rate}\" \"-model.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Stop Run All here\n",
    "assert False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Reload imports in the case that they are changed\n",
    "from importlib import reload\n",
    "\n",
    "# If not loaded into cache yet, import them\n",
    "import model_flower\n",
    "import model_train\n",
    "import model_test\n",
    "\n",
    "reload(model_flower)\n",
    "reload(model_train)\n",
    "reload(model_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_model = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
